<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>note/game/game-theory/game-theory.org</title>
</head>
<body>
<pre style="white-space: pre-wrap;">#+title: game theory

* refs

  - <a href="https://www.youtube.com/playlist?list=PLxjwC9b4YxZ4geaCLwrIUONYdRKXJo9XJ">https://www.youtube.com/playlist?list=PLxjwC9b4YxZ4geaCLwrIUONYdRKXJo9XJ</a>

* definition

  - game is about players and decision making

* model

  - to model game, we need to model
    actions of players
    and payoffs (or utility)

* normal-form

  - <a href="https://en.wikipedia.org/wiki/Normal-form_game">https://en.wikipedia.org/wiki/Normal-form_game</a>

  - players move simultaneously

  - table of payoffs of actions -- tensors

  - strategies can encode many things

    - x - game semantic of logic?

  - 2-player game is a matrix
    we have row-player and col-player
    row is indexed by actions of row-player
    col is indexed by actions of col-player
    each element of in matrix is a payoff-map
    from the players to its payoff

    - for n-player game
      each player is a dimension

  - x -
    the payoff in the model is just a number
    while in real life the payoff might can not be reduce to a number

    the payoff might be in a structure whose elements are not order-able

* game.nf

  #+begin_src cicada
  player-t : type
  payoff-t : type
  action-t = (player-t) -&gt; type

  game-t = conj {
    player-vect : vect-t (player-t, :n)
    nof-players = :n
    utility : (
      strategy-profile : vect-t ([p : player-t, action-t (p)], :n)
    ) -&gt; vect-t ([player-t, payoff-t], :n)
  }
  #+end_src

  - x -
    can two players in the same game be the same person?

  - game of pure competition -- zero sum game

  #+begin_src cicada
  payoff-map.range.sum () = 0
  #+end_src

  - game of pure cooperation
    - the structure can be simplified
      payoff-map is just one payoff

  #+begin_src cicada
  for x in payoff-map.range {
      x = :the-same-payoff
  }
  #+end_src

* game.nf -- simple action

  #+begin_src cicada
  player-t : type
  payoff-t : type
  action-t : type

  game-t = conj {
    player-vect : vect-t (player-t, :n)
    nof-players = :n
    utility : (
      strategy-profile : vect-t ([player-t, action-t], :n)
    ) -&gt; vect-t ([player-t, payoff-t], :n)
  }
  #+end_src

* nash equilibrium

  - <a href="https://en.wikipedia.org/wiki/Nash_equilibrium">https://en.wikipedia.org/wiki/Nash_equilibrium</a>

  - strategic reasoning

  - opponent action
    best response
    nash equilibrium

* dominant strategy

  - strategy = choosing an action
    dominant strategy

  - strictly dominant and weak dominant

  - if a strategy is strictly dominanted by another strategy
    it is not rational to choose the dominanted strategy

  - iterative removal of strictly dominated strategies
    - assuming the player is rational
    to simplify the game

  - we do not remove weak dominated strategies
    because a weak dominated strategies might be best response

* prisoner&apos;s dilemma

  - for example,
    in prisoner&apos;s dilemma
    defect is the dominant strategy
    and both defect is the nash equilibrium

* pareto optimality

  - <a href="https://en.wikipedia.org/wiki/Pareto_efficiency">https://en.wikipedia.org/wiki/Pareto_efficiency</a>

  - an outsider (non player) is judging the outcome
    think some outcome is better than the other

  - the sum of payoffs might be used as the value

* mixed strategies

  - suppose a normal-form game will be played repeatedly.
    the space of strategy is changed
    from one (player-t, action-t)
    to (player-t, list-t (action-t))

  - but to implement it,
    we do not really assign payoffs to such huge space.

    instead we simplify the model a step further
    by supposing the list-t (action-t) is a random variable
    respecting some distribution

  - we need a new data type -- action-profile-t
    and a new interface function -- expected-utility

  - in this model,
    the strategy of a player
    is not (player-t, action-t)
    also not (player-t, list-t (action-t))
    but is (player-t, action-profile-t)

    the player is not choicing one action,
    but give all actions a probability of choice

    to calculate expected-utility,
    we calculate linear combination of actions
    using probability as coefficient

  - note that in this model
    there are not coordinations between players

    after a player decided a action profile -- a mixed strategy
    he must execute the strategy
    no matter what his opponent choice to do

* computing nash equilibrium of mixed strategy game

  - <a href="https://en.wikipedia.org/wiki/Linear_complementarity_problem">https://en.wikipedia.org/wiki/Linear_complementarity_problem</a>

  - Linear programming
    <a href="https://en.wikipedia.org/wiki/Linear_programming">https://en.wikipedia.org/wiki/Linear_programming</a>
    - 此英文术语 翻译为 线性规划
      与编程无关

* game theory solution concept

  - nash equilibrium is an example of game theory solution concept

  - another example of game theory solution concept is
    correlated equilibrium intuition

    in which the model of mixed strategy is changed
    coordinations is allowed

    - an example of such correlated equilibrium
      is traffic light

* maxmin strategy

  - a player maximize his worst case payoff
    - assuming opponents are trying to hurting him

  - the payoff of a player&apos;s maxmin strategy
    is called his safety value

  - minmax strategy
    a player minimize other opponents&apos; best payoff
    - assuming opponents are trying to gain the most for themselves

  - minmax theorem -- by von neumann
    <a href="https://en.wikipedia.org/wiki/Min-max_theorem">https://en.wikipedia.org/wiki/Min-max_theorem</a>

* extensive-form -- game tree

  - <a href="https://en.wikipedia.org/wiki/Extensive-form_game">https://en.wikipedia.org/wiki/Extensive-form_game</a>

  - includes timing of moves

    - even only a single action will be made
      reasoning about the future still need the concept of time

  - players move sequentially

  - keep track of decisions

* perfect-information game

  - example of extensive-form model

  - x -
    during the study of extensive-form model
    people try to reuse concepts learned
    from the study of normal-form model

    the following definitions are reused
    - pure strategy
    - pure best response
    - pure nash equilibrium
    - mixed strategy
    - mixed best response
    - mixed nash equilibrium

* subgame perfection nash equilibrium

  - if the nash equilibrium is sitll nash equilibrium
    in every subgame

  - this definition rules out non-credible threats

* backward induction algorithm

  - aim
    - calculate utility at root
    - find subgame perfection nash equilibrium

  - minmax algorithm
</pre>
</body>
</html>
