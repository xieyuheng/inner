#+title: Function compose, Type cut, and The algebra of logic

- Author : Xie Yuheng
- Date : 2016-06-14
- Keywords : Language design, Dependent type, Deduction system, Sequent calculus, Algebraic structure.

* abstract

  - some said,
    [for example, see the wikipedia page of "Curry–Howard correspondence", at the time when this paper is written]
    in the framework of Curry–Howard correspondence,
    Gentzen's sequent calculus does not correspond with
    a well-defined pre-existing model of computation,
    as it was for Hilbert-style and natural deduction.

    - in this paper, I will show that
      we can get what sequent calculus corresponds to,
      not by designing a new model of computation,
      but by changing the syntax of well known model.

    - I will show that
      sequent calculus corresponds to a functional programming language,
      the syntax of which is optimized for function composition
      instead of function application.

    - I will also show the trade-off of this syntax design.
      1. the syntax of type and function-body are unified.
      2. we lose the implicit syntax for currying.
      3. we gain the algebraic associative law.

  - some also said, [for example, see the first chapter of "Homotopy Type Theory"]
    deduction system can be viewed as algebraic structure,
    where theorems are the elements (like elements of group),
    where deductive rules are the operations (like multiplication of group).

    - in this paper, I will show that
      with the associative law which we obtained from function composition,
      the corresponding deduction system of our programming language
      not merely "can be viewed as" algebraic structure,
      but actually has a very rich algebraic structure.

  - I will also introduce a prototype implementation of such a language.
    I call it "sequent1".

* background

*** how the idea was conceived

    - two years ago,
      for some reason, I learned the design of the stack-based language -- forth.
      I began to write my own forth-like language,
      and tried to add various features to it.
      soon I found another forth-like language -- joy.
      from joy I learned the composition vs. application trade-off in syntax.

    - I added more and more features to my forth-like language.
      things went well, until I tried to add a type system to the it.
      I found that
      to design a good type system,
      a designer has to know Curry–Howard correspondence well.

    - and after some learning,
      I figured that
      the composition vs. application trade-off in syntax,
      corresponds to
      the sequent-calculus vs. natural-deduction in proof theory.

    - I tried to add such a sequent-calculus type system
      to the forth-like language several times.
      I failed.
      because the implementation is written in assembly language,
      the low-level detailed code would soon exceed the complexity
      that a normal people like me can manage.

    - I steped back.
      I decided to write a prototype language in scheme.
      the prototype only limited to demonstrate the main idea of "sequent-calculus as type system".
      thus I wrote "sequent1".

*** related works

    - there are many other works
      that assign computational models to sequent-calculus-like logics.
      for example :
      | people         | logic        | model                  |
      |----------------+--------------+------------------------|
      | Frank Pfenning | linear logic | concurrent programming |

    - maybe one logic system can correspond to multiple computational models.
      maybe more terminologys should be carefully coined,
      and more general framework theory should be wisely designed,
      to describe correspondences between deduction systems and computational models.

* the change of syntax

  - I will introduce my syntax by comparing it with
    the syntax of an imaginary agda-like (or idris-like) language.
    I will mark its syntax by << application-language >>,
    and I will mark my syntax by << composition-language >>.

*** natural number

    - << application-language >>
      #+begin_src idris
      data natural : type where
        zero : natural
        succ : natural -> natural

      add : natural -> natural -> natural
      add zero n = n
      add (succ m) n = succ (add m n)

      mul : natural -> natural -> natural
      mul zero n = zero
      mul (succ m) n = add n (mul m n)
      #+end_src

    - note that,
      in the following examples
      "~" can be read as "define-function",
      "+" can be read as "define-type".

    - << composition-language >>
      #+begin_src scheme
      (+ natural (-> type)
         zero (-> natural)
         succ (natural -> natural))

      (~ add (natural natural -> natural)
         (:m zero -> :m)
         (:m :n succ -> :m :n add succ))

      (~ mul (natural natural -> natural)
         (:m zero -> zero)
         (:m :n succ -> :m :n mul :m add))
      #+end_src

*** detailed explanation of above example

    - explanation
      #+begin_src scheme
      (note
        the second arrow of the function body of
        (~ mul (natural natural -> natural)
           (:m zero -> zero)
           (:m :n succ -> :m :n mul :m add))
        which is
        (:m :n succ -> :m :n mul :m add)
        (note
          the antecedent of (:m :n succ -> :m :n mul :m add)
          is (:m :n succ)
          it can be viewed as 3 functions composed together
          the type of each of them are showed by the following list
          ((:m (-> natural))
           (:n (-> natural))
           (succ (natural -> natural)))
          the resulting type is
          (-> natural natural))
        (note
          the succedent of (:m :n succ -> :m :n mul :m add)
          is (:m :n mul :m add)
          it can be viewed as 4 functions composed together
          the type of each of them are showed by the following list
          ((:m (-> natural))
           (:n (-> natural))
           (mul (natural natural -> natural))
           (:m (-> natural))
           (add (natural natural -> natural)))
          the resulting type is
          (-> natural)))
      #+end_src

*** currying must also be explicit

    - in type, input arguments and return values are made explicit.
      instead of (natural -> natural -> natural),
      we write (natural natural -> natural).

    - thus, in function body, currying must also be explicit.
      we lost the implicit syntax for currying.
      because currying is designed as a convention
      for the syntax of function application.

*** vector

    - << application-language >>
      #+begin_src idris
      data vector : natural -> type -> type where
        null : vector zero t
        cons : t -> vector n t -> vector (succ n) t

      append : vector m t -> vector n t -> vector (add m n) t
      append null       l = l
      append (cons e r) l = cons e (append r l)

      map : (m : a -> b) -> f a -> f b
      map f null       = null
      map f (cons e l) = cons (f e) (map f l)
      #+end_src

    - << composition-language >>
      #+begin_src scheme
      (+ vector (natural type -> type)
         null (-> zero :t vector)
         cons (:n :t vector :t -> :n succ :t vector))

      (~ append (:m :t vector :n :t vector -> :m :n add :t vector)
         (:l null -> :l)
         (:l :r :e cons -> :l :r append :e cons))

      (~ map (:n :t1 vector (:t1 -> :t2) -> :n :t2 vector)
         (null :f -> null)
         (:l :e cons :f -> :l :f map :e :f apply cons))
      #+end_src

*** unified syntax

    - the syntax of type and function-body are unified.
      a type is an arrow, a function-body is a list of arrows.

*** different optimization of syntax

***** for function composition

      - << application-language >>
        #+begin_src idris
        compose : {A B C : type} (A -> B) -> (B -> C) -> (A -> C)
        compose f g = λ x -> (f (g x))
        #+end_src

      - << composition-language >>
        the syntax is optimized for function composition.
        function composition is expressed by term concatenation.

***** for function application

      - << application-language >>
        the syntax is optimized for function application.
        function application is expressed by term concatenation.

      - << composition-language >>
        #+begin_src scheme
        (~ apply (:a :b ... (:a :b ... -> :c :d ...) -> :c :d ...)
           (note it is implemented as a primitive-function))
        #+end_src

*** stack processing

    - multiple return values are easily handled,
      and stack-processing functions can be used to help to
      re-order return values (without naming them) for function composition.
      (just like in forth & joy)

    - << composition-language >>
      #+begin_src scheme
      (~ drop (:t ->)
         (:d ->))

      (~ dup (:t -> :t :t)
         (:d -> :d :d))

      (~ over (:t1 :t2 -> :t1 :t2 :t1)
         (:d1 :d2 -> :d1 :d2 :d1))

      (~ tuck (:t1 :t2 -> :t2 :t1 :t2)
         (:d1 :d2 -> :d2 :d1 :d2))

      (~ swap (:t1 :t2 -> :t2 :t1)
         (:d1 :d2 -> :d2 :d1))
      #+end_src

* the correspondence

  - to show Curry–Howard correspondence under this syntax
    is to show,
    1. how to view type as theorem ?
    2. how to view function as proof ?

*** type as theorem

    - with the ability to handle multiple return values,
      we can express "and" easily.
      #+begin_src scheme
      (A B -> C D) -- "(A and B) implies (C and D)"
      #+end_src
      we can express "for all" and "there exist" in an unified way.
      #+begin_src scheme
      ((:x : A) -> :x P) -- "for all x belong to A, we have P(x)"
      (-> (:x : A) :x P) -- "there exist x belong to A, such that P(x)"
      #+end_src

    - I call expression of form (A B C ... -> E F G ...) sequent.
      but you should note that,
      sequent for us, is not exactly the same as sequent for Gentzen.
      Gentzen views succedent as "or", while we view succedent as "and".
      #+begin_src scheme
      for Gentzen -- (A B -> C D) -- "(A and B) implies (C or D)",
      for us      -- (A B -> C D) -- "(A and B) implies (C and D)".
      #+end_src

*** function as proof

    - "function as proof" means,
      the way we write function body forms a language to record deduction.
      a record of many steps of deduction is called a proof.

    - let us summarize deductive rules in sequent calculus in our language.
      I will omit some explicit contexts variables in the deductive rules,
      because in our language contexts can be implicit.

***** cut

      - cut
        #+begin_src scheme
        f : (A -> B)
        g : (B -> C)
        --------------
        f g : (A -> C)
        #+end_src

***** structural

      - left-weakening
        #+begin_src scheme
        f : (A -> C)
        -------------------
        drop f : (A B -> C)
        #+end_src

      - left-contraction
        #+begin_src scheme
        f : (A A -> B)
        ----------------
        dup f : (A -> B)
        #+end_src

      - right-contraction
        #+begin_src scheme
        f : (A -> B B)
        -----------------
        f drop : (A -> B)
        #+end_src

      - left-permutation
        #+begin_src scheme
        f : (A B -> C)
        -------------------
        swap f : (B A -> C)
        #+end_src

      - right-permutation
        #+begin_src scheme
        f : (A -> B C)
        -------------------
        f swap : (A -> C B)
        #+end_src

***** and

      - left-and-1
        #+begin_src scheme
        f : (A -> C)
        -------------------
        drop f : (A B -> C)
        #+end_src

      - left-and-2
        #+begin_src scheme
        f : (B -> C)
        ------------------------
        swap drop f : (A B -> C)
        #+end_src

      - right-and
        #+begin_src scheme
        f : (A -> B)
        g : (C -> D)
        ----------------------------
        g swap f swap : (A C -> B D)
        #+end_src

***** or

      - right-or-1
        #+begin_src scheme
        f : (A -> B)
        -------------------
        f : (A -> (B or C))
        #+end_src

      - right-or-2
        #+begin_src scheme
        f : (A -> C)
        -------------------
        f : (A -> (B or C))
        #+end_src

      - left-or
        #+begin_src scheme
        f : (A -> B)
        g : (C -> D)
        -----------------------------
        (case (:x {:x : A} -> :x f)
              (:y {:y : C} -> :y g))
        : ((A or C) -> (B or D))
        #+end_src

***** implies

      - left-implies
        #+begin_src scheme
        f : (A -> B)
        g : (C -> D)
        --------------------------
        (:a :h -> :a f :h apply g)
        : (A (B -> C) -> D)
        #+end_src

      - right-implies
        #+begin_src scheme
        f : (A B -> C)
        -----------------------
        (:x -> (:y -> :x :y f))
        : (A -> (B -> C))
        #+end_src

*** examples

    - have-equal-human-rights
      - in the following example
        "*" can be read as "define-hypothesis"
      #+begin_src scheme
      (* rich-human (:x is-rich -> :x is-human))
      (* poor-human (:x is-poor -> :x is-human))
      (* human-have-equal-human-rights
         (:x is-human :y is-human -> :x :y have-equal-human-rights))

      (~ rich-and-poor-have-equal-human-rights
         (:x is-rich :y is-poor -> :x :y have-equal-human-rights)
         (:ri :po -> :ri rich-human
                     :po poor-human
                     human-have-equal-human-rights))
      #+end_src

    - map/has-length
      #+begin_src scheme
      (+ list (type -> type)
         null (-> :t list)
         cons (:t list :t -> :t list))

      (~ map (:t1 list (:t1 -> :t2) -> :t2 list)
         (null :f -> null)
         (:l :e cons :f -> :l :f map :e :f apply cons))

      (+ has-length (:t list natural -> type)
         null/has-length (-> null zero has-length)
         cons/has-length (:l :n has-length -> :l :a cons :n succ has-length))

      (~ map/has-length (:l :n has-length -> :l :f map :n has-length)
         (null/has-length -> null/has-length)
         (:h cons/has-length -> :h map/has-length cons/has-length))
      #+end_src

    - natural-induction
      #+begin_src scheme
      (+ natural (-> type)
         zero (-> natural)
         succ (natural -> natural))

      (~ natural-induction
         ((:p : (natural -> type))
          zero :p apply
          ((:k : natural) :k :p apply -> :k succ :p apply)
          (:x : natural) -> :x :p apply)
         (:q :q/z :q/s zero -> :q/z)
         (:q :q/z :q/s :n succ ->
             :n
             :q :q/z :q/s :n natural-induction
             :q/s apply))
      #+end_src

* algebra of logic

  - a concrete (not abstract) algebraic structure is rich when
    1. its elements have practical meaning.
    2. it is equipped with many algebraic laws,
       which you can use to transform equations.

  - a good example of such rich concrete algebraic structure
    is the field of multivariate rational function
    (i.e. quotient (or fraction) of multivariate polynomials),
    which is studied in algebraic geometry.

  - since function composition already satisfies associative law,
    we have the opportunity to demonstrate an rich algebraic structure,
    the elements of which are formal theorems.

  - we will try to define those algebraic operations that are closed in the set of derivable theorems.
    hopefully we will be able to capture all deductions by algebraic operations.

*** to mimic fraction of natural number

    - let us view theorem (A -> B) as fraction,
      A as denominator,
      B as numerator.
      - just like (A \ B).
        note that,
        we are using reverse-slash instead of slash,
        to maintain the order of A B in (A -> B).

*** multiplication

    - to multiply two theorems (A -> B) and (C -> D),
      we get (A C -> B D).
      - just like (A \ B) (C \ D) = (A C \ B D).

      #+begin_src scheme
      (* r (A -> B))
      (* s (C -> D))

      (~ r/s/mul (A C -> B D)
         (:x :y -> :x r :y s))

      ;; abstract it to a combinator
      (~ general/mul
         ((:a -> :b) (:c -> :d) -> (:a :c -> :b :d))
         (:r :s -> (lambda (:a :c -> :b :d)
                     (:x :y -> :x :r apply :y :s apply))))
      #+end_src

    - theorems under multiplication is an Abelian group.
      identity element is (->).
      inverse of (A -> B) is (B -> A).

*** two definitions of addition

***** first definition

      - this definition recalls the fraction of natural number,
        but it seems not natural when written as function in our language.

      - to add two theorems (A -> B) and (C -> D),
        we get (A B -> (B C or A D)).
        - just like (A \ B) + (C \ D) = (A C \ (B C + A D)).

        #+begin_src scheme
        (* r (A -> B))
        (* s (C -> D))

        (~ r/s/fraction-add (A C -> (B C or A D))
           (:x :y -> :x r :y)
           (:x :y -> :x :y s))

        ;; abstract it to a combinator
        (~ general/fraction-add
           ((:a -> :b) (:c -> :d) -> (:a :c -> (:b :c or :a :d)))
           (:r :s -> (lambda (:a :c -> (:b :c or :a :d))
                       (:x :y -> :x :r apply :y)
                       (:x :y -> :x :y :s apply))))
        #+end_src

      - distributive is just like fraction of natural number,
        because the way we define addition
        is just like the addition of fraction of natural number.

      - theorems under addition is an Abelian semigroup.
        we do not have identity element,
        and we do not have inverse.
        - of course, we can introduce a "zero-theorem"
          (a theorem that we can never prove)
          as the identity element of addition,
          to make our algebraic structure more like fraction of natural number.

      - under this definition of addition,
        one may call the algebraic structure "natural field",
        to recall its similarites between the fraction of natural number.
        - note that,
          other terms like 'semi-field' is ambiguous.
          because it does not inform us
          whether we mean addition is semi or multiplication is semi.

***** second definition

      - this definition seems more natural in our language.

      - to add two theorems (A -> B) and (C -> D),
        we get ((A or B) -> (C or D)).

        #+begin_src scheme
        (* r (A -> B))
        (* s (C -> D))

        (~ r/s/mul-like-add ((A or C) -> (B or D))
           (:x {:x : A} -> :x r)
           (:y {:y : C} -> :y s))

        ;; abstract it to a combinator
        (~ general/mul-like-add
           ((:a -> :b) (:c -> :d) -> ((:a or :c) -> (:b or :d)))
           (:r :s -> (lambda ((:a or :c) -> (:b or :d))
                       (:x {:x : :a} -> :x :r apply)
                       (:y {:y : :c} -> :y :s apply))))
        #+end_src

      - distributive also hold under this definition of addition,
        because (-> A (B or C)) is the same as (-> (A B or A C)).

      - theorems under addition is an Abelian semigroup.
        identity element is (->),
        but we do not have inverse.

*** term-lattice, and cut as weaken

    - this is where we must take term-lattice into account.

      | term                   | lattice          |
      |------------------------+------------------|
      | unification (uni)      | meet             |
      | anti-unification (ani) | join             |
      | cover (or match)       | greater-or-equal |

      - note that,
        "equal" can be defined by "greater-or-equal".

    - term-lattice is also called "subsumption lattice" by other authors.
      I call it "term-lattice",
      because I want to make explicit its relation with term-rewriting-system
      (I will address the detail of term-lattice in another paper).

    - if we have (A -> B) and (C -> D),
      we can cut them only when (C cover B).
      for example, when :
      - C = B
      - C = (B or E)
      - C = :x :y P
        B = :x :x P

    - cut can be viewed as an important way to weaken a theorem.
      we can first multiply (A -> B) and (C -> D) to (A C -> B D),
      then weaken it to (A -> D), provides that (C cover B).

    - we can also extend the lattice operations to cedent (antecedent and succedent),
      because cedent is Cartesian product of term.

*** equality of theorem

    - we can define A == B, as (A -> B) and (B -> A).

*** constructiveness

    - in our language, we have the following keywords to do definitions :
      | keyword | read as                                | function-body |
      |---------+----------------------------------------+---------------|
      | "+"     | define-type, define-data               | trivial       |
      | "~"     | proof, define-theorem, define-function | non-trivial   |
      | "*"     | assume, define-hypothesis              | no            |

    - whenever we have function-body, be it trivial or non-trivial,
      we can use it to rewrite data.
      - for example,
        the function-body of "succ" is trivial,
        it rewrites "zero" to "zero succ",
        i.e. merely add a symbol to the data.
        while the function-body of "add" is non-trivial,
        it rewrites "zero succ zero succ" to "zero succ succ".

    - whenever we use "*" to introduce a hypothesis,
      the constructiveness of function is lost,
      although we still can use it to define functions
      and type check the definitions,
      we can not use it to rewrite data.
      (but abstractiveness is gained,
      I will address the detail of the balance
      between constructiveness and abstractiveness in another paper)

*** algebraic extension

    - then defining a new types by "+",
      we provide a type-constructor,
      and a list of data-constructors.

    - by introducing such constructors,
      we are extending our algebraic structure.
      (just like field extension by root of equations)

* implementation

  - I made an attempt to implement a prototype of the language,
    project page at http://xieyuheng.github.io/sequent1

*** implementation-tech

    - during writing the prototype language,
      I noticed the language is not necessarily stack-based.
      and we have the following relations :

      | implementation-tech     | the natural of language       |
      |-------------------------+-------------------------------|
      | stack-based computation | call-by-value (non-lazy-eval) |
      | term-rewriting-system   | call-by-name (lazy-eval)      |
      | graph-rewriting-system  | call-by-need (lazy-eval)      |

    - first few versions of sequent1 is implemented as a stack-based language,
      only later, changed to term-rewriting-system.
      because we have to handle lazy-trunk in the language,
      and in a term-rewriting-system,
      I can handle lazy-trunk in an unified implicit way.

*** mistakes in my implementation

    - (1) I fail to far see that
      the structure of reports, which returned by various checkers,
      must be highly structured data, instead of string.
      thus, I fail to print useful reports when checkers find mistakes in code.

    - (2) I know graph-rewriting-system is needed,
      but I did not implement the language by it.
      because I want to keep the prototype simple.

    - (3) can not handle mutual recursive function.

    - (4) can not handle un-named "or".

    - (5) the meaning of equality is not fully understood.

    - (6) not yet designed a good mechanism for abstractiveness.

    - I will correct these mistakes in next versions of the prototype.

* further work

  - (1) I planed to do develop the algebra of logic further.

  - (2) I know that with carefully handled "equality",
    I will be able to use the language as a concrete tool
    to investigate algebraic topology.

* appendixes

*** rationale of using postfix notation

    - in the linear writing system of our language,
      we can roughly distinguish four kinds of notations for function or predicate :
      | infix     | ((1 + 2) + 3) |
      | prefix    | + + 1 2 3     |
      | postfix   | 3 2 1 + +     |
      | borderfix | (+ 1 2 3)     |
      - infix is especially good for associative binary function.
      - prefix and postfix are not ambiguous without bracket.
      - borderfix can be used for functions
        that can apply to different numbers of arguments.

    - my choice is between prefix and postfix,
      because for simplicity I need the following two features :
      - the arity of all functions must be fixed
      - we want our expressions to be not ambiguous without bracket

    - then, how do I decide to use postfix instead of prefix ?
      seemingly, prefix and postfix are symmetric,
      while we still can distinguish them.
      because we write in special order
      (from left to right in most western language).
      - in postfix notation suppose we have written :
        1 2 +
        and we want to add 3 to the result of 1 2 +,
        we simply write :
        1 2 + 3 +
      - while in prefix notation suppose we have written :
        @@html: + 1 2 @@
        and we want to add 3 to the result of + 1 2,
        we have to insert + 3 in front of + 1 2 and write :
        @@html: + 3 + 1 2 @@

    - I summarize the above difference by say :
      postfix notation respect the special order of a linear writing system.
      thus, I use postfix notation.

*** remark on deduction and inference

    - one might ask, what is a deduction or a inference ?
      my answer is,
      a deduction or a inference is a way to express a change of theorem.
      ("a change" means "one step of change")

    - let us generalize it a little bit,
      and to discuss "a change of thing" and "language to record changes".
      you will find these two concepts are very common,
      and they are also named differently in different places :
      | thing   | a change of thing     | language to record changes |
      |---------+-----------------------+----------------------------|
      | theorem | deduction             | proof                      |
      | food    |                       | cookbook                   |
      | data    |                       | algorithm                  |
      | number  | elementary arithmetic |                            |
      (seems to me like a market for language designers)
